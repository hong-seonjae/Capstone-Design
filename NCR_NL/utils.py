import os
import shutil
import json

import torch
import numpy as np

from scipy.stats import norm
from matplotlib import pyplot as plt


class AverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, name="", fmt=":f"):
        self.name = name
        self.fmt = fmt
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

    def __str__(self):
        fmtstr = "{name} {val" + self.fmt + "} ({avg" + self.fmt + "})"
        return fmtstr.format(**self.__dict__)


class ProgressMeter(object):
    def __init__(self, num_batches, meters, prefix=""):
        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)
        self.meters = meters
        self.prefix = prefix

    def display(self, batch):
        entries = [self.prefix + self.batch_fmtstr.format(batch)]
        entries += [str(meter) for meter in self.meters]
        print("\t".join(entries))

    def _get_batch_fmtstr(self, num_batches):
        num_digits = len(str(num_batches // 1))
        fmt = "{:" + str(num_digits) + "d}"
        return "[" + fmt + "/" + fmt.format(num_batches) + "]"


def save_config(opt, file_path):
    with open(file_path, "w") as f:
        json.dump(opt.__dict__, f, indent=2)


def load_config(opt, file_path):
    with open(file_path, "r") as f:
        opt.__dict__ = json.load(f)


def save_checkpoint(state, is_best, filename="checkpoint.pth.tar", prefix=""):
    tries = 15
    error = None

    # deal with unstable I/O. Usually not necessary.
    while tries:
        try:
            torch.save(state, prefix + filename)
            if is_best:
                shutil.copyfile(prefix + filename, prefix + "model_best.pth.tar")
        except IOError as e:
            error = e
            tries -= 1
        else:
            break
        print("model save {} failed, remaining {} trials".format(filename, tries))
        if not tries:
            raise error


def adjust_learning_rate(opt, optimizer, epoch):
    """Sets the learning rate to the initial LR
       decayed by 10 every 30 epochs"""
    lr = opt.learning_rate * (0.1 ** (epoch // opt.lr_update))
    for param_group in optimizer.param_groups:
        param_group["lr"] = lr

def write_file(opt, out, option="validation"):
    if option == "validation":
        save_path = os.path.join(opt.output_dir, opt.save_validation_result)
    else:
        save_path = os.path.join(opt.output_dir, opt.save_loss_result)
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    with open(f"{save_path}", "a") as f:
        f.write(f"{out}\n")

def save_split_indices(opt, epoch, labeled_idx_A, unlabeled_idx_A, labeled_idx_B, unlabeled_idx_B):
    save_path = os.path.join(opt.output_dir, f"split_idx_epoch_{epoch}.npz")
    np.savez(
        save_path,
        labeled_A=labeled_idx_A,
        unlabeled_A=unlabeled_idx_A,
        labeled_B=labeled_idx_B,
        unlabeled_B=unlabeled_idx_B
    )